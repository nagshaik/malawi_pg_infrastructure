apiVersion: v1
kind: ConfigMap
metadata:
  name: logstash-pipeline
  namespace: logging
data:
  logstash.conf: |
    input {
      # TCP input for application logs
      tcp {
        port => 5000
        codec => json
        tags => ["tcp"]
      }
      
      # HTTP input for webhook logs
      http {
        port => 8080
        codec => json
        tags => ["http"]
      }
      
      # Beats input (for Filebeat if needed)
      beats {
        port => 5044
        tags => ["beats"]
      }
    }
    
    filter {
      # Parse JSON if not already parsed
      if [message] =~ /^\{.*\}$/ {
        json {
          source => "message"
          skip_on_invalid_json => true
        }
      }
      
      # Add timestamp if missing
      if ![timestamp] and ![@timestamp] {
        ruby {
          code => "event.set('timestamp', Time.now.utc.iso8601)"
        }
      }
      
      # Parse Kubernetes metadata from log path
      if [kubernetes] {
        mutate {
          add_field => {
            "k8s_namespace" => "%{[kubernetes][namespace_name]}"
            "k8s_pod" => "%{[kubernetes][pod_name]}"
            "k8s_container" => "%{[kubernetes][container_name]}"
            "k8s_node" => "%{[kubernetes][node_name]}"
          }
        }
      }
      
      # Extract log level
      if [message] {
        grok {
          match => {
            "message" => [
              "%{LOGLEVEL:log_level}",
              "\[%{LOGLEVEL:log_level}\]",
              "level=%{LOGLEVEL:log_level}",
              "\"level\":\"%{LOGLEVEL:log_level}\""
            ]
          }
          tag_on_failure => []
        }
      }
      
      # Normalize log level to uppercase
      if [log_level] {
        mutate {
          uppercase => ["log_level"]
        }
      }
      
      # Add environment metadata
      mutate {
        add_field => {
          "environment" => "malawi-pg"
          "cluster" => "malawi-pg-azampay-eks-cluster"
          "region" => "eu-central-1"
        }
      }
      
      # Parse application-specific fields
      if [app] {
        mutate {
          add_field => { "application" => "%{app}" }
        }
      } else if [service] {
        mutate {
          add_field => { "application" => "%{service}" }
        }
      }
      
      # Parse HTTP logs
      if "http" in [tags] {
        if [request] {
          grok {
            match => {
              "request" => "%{WORD:http_method} %{URIPATH:http_path}(?:%{URIPARAM:http_query})?"
            }
            tag_on_failure => []
          }
        }
      }
      
      # Add geolocation for IP addresses (optional)
      if [client_ip] {
        geoip {
          source => "client_ip"
          target => "geoip"
        }
      }
      
      # Remove unnecessary fields
      mutate {
        remove_field => ["agent", "ecs", "input", "host"]
      }
      
      # Handle errors
      if "_jsonparsefailure" in [tags] {
        mutate {
          add_field => { "parse_error" => "JSON parsing failed" }
        }
      }
    }
    
    output {
      # Output to OpenSearch
      opensearch {
        hosts => ["${OPENSEARCH_ENDPOINT}"]
        user => "${OPENSEARCH_USER}"
        password => "${OPENSEARCH_PASSWORD}"
        index => "logstash-%{+YYYY.MM.dd}"
        ssl => true
        ssl_certificate_verification => true
        
        # Template management
        manage_template => true
        template_name => "logstash"
        template_overwrite => true
        
        # Retry logic
        retry_on_conflict => 5
        
        # ILM Policy
        ilm_enabled => false
      }
      
      # Debug output (comment out in production)
      # stdout {
      #   codec => rubydebug
      # }
      
      # Dead letter queue for failed messages
      if "_opensearchoutputfailure" in [tags] {
        file {
          path => "/usr/share/logstash/data/dead_letter_queue/%{+YYYY.MM.dd}.log"
          codec => json_lines
        }
      }
    }
